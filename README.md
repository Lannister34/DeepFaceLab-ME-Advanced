# DeepFaceLab-ShenNong-神农汉化

汉化整合包下载地址：https://pan.baidu.com/s/1TLubJ2FwABG_1B2kUpvMZg?pwd=cru3 

GitHub存储空间以及文件上传大小限制，只是将来用来查询代码的修改记录，并不包含必要的模型文件和环境依赖
-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年5月23日：
v3.0.1版本：

1.重磅更新：增加了MVE提供的另一种训练窗口，可远程访问，Linux也可实时预览和操作快捷键！

2.检查bat等细节和命名的错误，如果有疏漏请反馈。用户交互不影响模型质量

3.实在是没找到预览图左下角的 ???.jpg 在哪个变量，知道的人请告诉我！解决一下字符显示问题

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年5月22日：
v3.0.0版本：

1.修复了模型从其他版本升级神农后缺少参数而报错。处理方式是强制询问

2.解决了：选择模型后先弹出摘要，再修改参数（如果参数缺了，就会在显示摘要前崩溃，从而无法修改参数，死循环了）。Xseg训练也解决了。
现在弹出摘要之前如果检测到参数有缺，就会强制进入设置参数的环节！这个问题尝试用三四种方式修复，直到这次版本估计才一劳永逸！

3.解决了预览窗口汉字变成乱码的问题

4.预览窗口的loss显示优化：尤其是 dst不再直接覆盖在src导致盲区，交集将会显示绿色。尝试过红紫蓝的配色，辨识度不如黄绿蓝

5.新世代的功能 已成功测试：Xseg的评判标准在于手画素材量以及loss，换脸模型的评判标准在于素材数量以及loss。迭代数并不是最好的参照

6.将会恢复训练显存的记录，我不希望大家攀比，但是很多时候是作为判断模型能否运行的诊断。报错之后只要截图摘要就知道了。

7.后续版本将会对pak动手脚，使其可以由列表来进行选择。并且记录不同pak的loss以反馈训练阶段。如果数据是记录在pak的，我还想顺便做一下密码设定，
这样远程训练就可以保护素材避免被盗取。

8.由于现在python环境已统一到唯一目录。为将来部分文件编译为pyd打下基础（我觉得pyc就行了）尤其是涉及到资产安全的部分。
在dfl领域是首个把N卡和A卡放到同一个python环境，且同步更新软件功能。

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年5月17日：
v2.6.1版本：

1.早期有过 Q224模型的导出dfm.bat，后来的版本不小心吃掉了。这次跟Q512一起出

2.Q512内测开启！快来尝鲜！流程只有两个选项。事先声明：不能练万能丹，适合一对一的直播专丹或者视频换脸。

3.流程优化：选择完模型后，先弹出模型摘要，再有10秒Enter时间决定是否修改。

4.Q512的预览图展开了。如果大家喜欢，我会把ME的也改成一样（5列取代2列）

5.WEBUI正式内测，我试过费两天功夫想改依赖的源码（已经代码混淆打包，非常难搞），所以干脆提示大家别点击右上角的下拉菜单就好（模型可能会崩）。
也不想汉化了，能点击的栏目也就左上角的3个而已，用来看loss图和预览图的！在服务器训练的可以访问外网ip:6006端口，Linux也能看预览图了！
刷新间隔是固定5分钟，可以改为1分钟，但是不能非等间距频率预览。

6.bat增加了许多，反复检查希望没有疏漏。

7.ME模型逐渐过渡命名为SN模型，预计下一个版本会做个自动改名

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年5月9日：
旷工的这段时间除了放假陪家人以外，还完成了另外的两个项目：ddos防火墙，在线文档免登录调用API的模块封装。
v2.5.1版本：

1.这次重点更新python环境，只有一个python文件夹了，原先是2个。
修复了2.3.3版本的config.txt逻辑失效。现在N卡和A卡的切换更骚了！

2.修正了old-SAEHD的txt 以UTF-8保存（感谢台湾同胞反馈的问题）

3.修正了2.4.1版本old训练器的参数颠倒。当时把gan放进了预训，导致正训没有gan选项。现在是预训不显示gan了。
放心，这个不影响模型的训练和兼容。只是UI体验的优化。

4.合成的时候缺文件。Exception: Unable to load FaceEnhancer.npy，已粘贴回原位
-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年4月26日：
v2.4.1版本：

1.镇坛之宝不能直接用，而是需要经过训练一下保存后才能用。
我不一定想去处理完这个问题，说白了就是神农训练后的遮罩模型会增加一个 resolution的参数，可能还有别的。
如果真要靠脚本写到原版遮罩，跟你们迭代1次然后保存 也是同样的效果。如果将来新增的参数多了，还要照顾原始版，就会多很多工作量了。
反正神农训练后的遮罩可以让官方原版、ICE、ME都能使用。如果神农要用原版或ME遮罩，只需要用神农训练一下保存就行。

2.合成的时候超分缺文件。Exception: Unable to load FaceEnhancer.npy
关于这个问题，从_internal\DeepFaceLab\facelib 拷贝到_internal\DeepFaceLab_old\facelib  就好了

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年4月25日：
v2.4.0版本：

1.之前256以外的遮罩有一定的限制，我今天看了才发现代码我是已经写好了，只是延期发布而已。
现在已解锁其他分辨率Xseg模型的应用与创建。

2.拥有的XS标记数据集由4000增加至数十万。不久后可达到数百万张
和Cxsmo合作，目前有重大突破。

3.好久没放出完整包了，这次在第八类bat里增加了一些工具，并且优化了速度。

4.神农网盘链接附赠224的SRC和DST素材（再次花了点时间整理和筛选），希望大家尝试一下Quick224.
训练不超过2天时间，导出dfm后看看效果，看有没有闪烁
我近几天也在亲自测试小模型（所以有点忙），用的也是附赠的素材。

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年4月23日：
v2.3.3版本：

1.新增一些工具，好东西应该让大家先用上！原作者如果需要灵石可以找我分。
【神农MVE-DFL汉化】v3.0.1

2.顺便把之前各种需要选择显卡和RG的bat，改成自动读取txt里的配置。

3.清理一些垃圾文件夹。其他的忘了，今天发生了些事，手忙脚乱

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年4月22日：
v2.3.2版本：

1.新增：5.4)--- 训练 SAEHD 继续上次 --------------------- train Recent SAEHD.bat
忽略模型和显卡列表以及参数，直接开始上次的训练。

2.记录GPU设备的选择并保存到options，为将来（选择模型后直接开始训练）做准备。
不想每次都询问GPU了。（温馨提示：模型小到一定程度的时候，双卡不如单卡快）

3.把SAEHD的显卡和RG配置保存到本地txt配置文件，由
0)———————————[ 显卡 设置 —— RG 开关 ]—————————————————————————————————
统一管理，不再每次都询问。

4.结合1和3，放个测试效果：总之就是双击即可自动训练，不用选择模型、显卡、显卡模式、RG，这四项。
【神农MVE-DFL汉化】v3.0.1

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年4月21日：
v2.3.0版本（完成，未传）：

1.正在规划3.0时代。这次先从dfl-SAEHD入手改动。
从头梳理模型训练脚本，省略无效参数！早期阶段就不会弹出GAN、style之类的选项。
【神农MVE-DFL汉化】v3.0.1

在正式版会先选择显卡，在选择模型，然后显示摘要，最后才修改参数。
而不是 选择模型--选择显卡--修改参数--显示摘要，  这种奇葩顺序。
更别说选项参数的顺序也很乱，创建新丹的时候分辨率居然不是在最开头。

2.有个毛病恶心了我很久了，神农有40个选项参数，当我设置完了，它告诉我（aligned里是空的）！
由于训练过程中需要替换和重命名素材，这种情况常发生。所以我让它先检测，该退出就退出，如果素材非空，才显示选项。
此功能牵扯到合成和导出，暂时先保持原状，等将来和pak命名一同优化！

3.由于梳理参数询问，解决了大家经常遇到的KeyError: 'retraining_samples'这类问题（强制询问）
在这里统一说原因：刚更换软件别懒到Enter都不点，直接就让它自生自灭。连试一试都懒。神农走一遍流程就行了。

4.Quick224在这个版本已支持导出dfm。Quick512、Quick384 正在路上

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年4月15日：
v2.2.0版本（补丁已发）：

1.对XSeg应用（Apply）进行了大整改，解决了旧版xs模型命名和分辨率固定256的问题。
同时兼顾了新模式的多遮罩选择列表、自定义分辨率。且如果遮罩文件夹里面只有一个模型（哪怕是旧版镇坛），
此时就会直接应用，而不弹出选择列表。

2.对于XS模型的summary表格，我不希望通过迭代数来论英雄。毕竟它可以修改、也可以继承。
我会记录用于XS训练的手标素材数量，以及当前的loss数值。也可以记录一个递增的版本号（学习ICE）

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年4月13日：
v2.1.2版本（补丁已删）：

1.改正了导出SAEHD模型.dat的py环境

2.更新覆盖了官方内置Xseg模型（包括合成的时候也默认用它）。不一定要使用自定义模型了。

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年4月12日：
v2.1.1版本：

1.处理了ME合成器的报错

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年4月8日：
v2.1.0版本：

1.在ME新增功能【超级扭曲】，DFL没必要加，因为自身已经扭得比较大了
介绍：ME和DFL原版的随机扭曲强度不同，其实DFL扭曲的幅度更大，所以哪怕迭代毫秒更快但是loss可能下降更慢，
当然也是大家常说到的DFL比ME更像SRC的原因。
经过调教，若是参数用力过猛，可能只适合从零开始练。（幅度大100%，未知风险大于收益，放弃实施）
为了兼容DFL原版底模，ME开启超级扭曲后，比DFL扭曲幅度大20%~25%。但是比ME本身大得多。

我还是直观给出数据！ME的旋转在[-2,2]  DFL旋转在[-10,10] 而ME超级扭曲[-12,12] .  缩放方面，ME的上限一直比DFL大一些
或许也是ME的BS经常要比DFL少2的原因之一
-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年4月4日：
v2.0.3版本（已上传）：

1.已检查SAEHD合成阶段，多模型需要修改的地方太多，暂时指定默认xseg256用于合成器

2.修复了原版转神农直接训练时 “缺少retrain loss” 参数的错误。现在不会在绘制表格的时候报错，但建议大家还是走一遍参数设置。

3.同时也解决了Xseg、Merge、Quick224 的参数缺失问题。其实就是绘制summary的环节各不相同 导致bug

4.神农384遮罩已收集数千张人工标记素材，准备训练。预计六月份左右会在外国友人的辅助下增加数十万张训练素材。
只要网友交作业，我就愿意分享统一成果。不会借口说 “我画了几万张但是网友只画了几百张 所以只能给个残缺版才公平。”
欢迎添砖加瓦！我个人的成果就是大家共享的成果！我从入行至今没有卖过任何一分钱东西（灵石我是提现不了的！），当然，我很需要得到捐赠或者订单。
我认为任何有实质壁垒的模型成果都不应该卖人民币，因为马上就会倒卖泛滥贬值。只有代练才能锁住这个生产资料的源头

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月30日：
v2.0.2版本：

1.如果有空就检查一下SAEHD合成阶段的多遮罩应用

2.已调试完成Quick224模型。极速训练

3.神农384神丹 目前发挥良好

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月28日：
v2.0.1版本：

0.上一版的Xseg训练实现了多模型共存，通过列表索引来选择。但测试发现，在应用遮罩的阶段是缺了 用户选择 流程。

1.重点修改Xseg的写入（apply）动作，它原版是不能选择列表的，且不属于模型基类。所以重写了获取XSeg列表索引

2.打个预防针：合成阶段可能也还暂时没列表（复制代码很快的）。如果出现这种情况，暂时用坛宝即可。

3.最新的坏消息是：非256Xseg模型的 应用与合成，有问题。大约需要一天时间修复。
这部分已经触及敏感代码了（非256XSeg模型的创建、写入、合成），打算保护一段时间直到我练出足够强的384，我就是要先垄断。

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月27日：
v2.0.0版本：

1.XSeg已经能支持自定义分辨率和解码维度。（这部分代码暂时不开放，预计百日内开源）
【XSeg遮罩】喜讯！创建或复训任意分辨率的遮罩（限时）

2.新增Quick224的训练和合成。测试阶段。总之是方便快速、新人无痛的必备之选！

3.summary之前只支持ME导致options对不上就报错，现在已经进行分类处理了。每种架构显示的表格都不同。

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月26日：
v1.9.4版本：

1.更改Xseg分辨率失败，已经努力了24小时 想尽办法了。将在2.0解决

2.SAEHD舍弃掉新版合成器。（你们删个bat或者不用就好了）
SAEHD用旧版，ME用新版。他们是一一对应的

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月22日：
v1.9.3版本：

1.检查原版SAE架构的表格与排版对齐
【神农MVE-DFL汉化】v3.0.1

2.测试了FP16的性能
已有最终定论：【新提醒】【神农汉化】RG | DML | FP16 非常重要的测评-【DFL】综合讨论-deepfacelab中文网 - Powered by Discuz! (dfldata.cc)

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月22日：
v1.9.2版本：

1.取消某地方的浮点数转整数，ME和SAEHD都使用最新的openCV4.7

2.全面优化目录bat的缺陷：【最新使用】现在不会重复复制自己了

3.给CMD窗口加标题

4.DML和RG可以手动控制切换了

5.修改了训练时 ME和SAE的随机扭曲程度，使二者都取了一个折中值。
比如ME是2，SAE是10，我就让他俩都取5

6.根据代码的不完全证据表明：512的模型在ME训练需要用到1024切脸，512模型在原DFL训练需要用到768切脸
还没彻底论证，只是看到了缩放方面的函数

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月21日：
v1.9.0版本（提前预告）：

1.SAEHD的 图形设置-硬件加速gpu计划 提示语 变为 “初始化.bat”自动设置。
我一直觉得它很烦人，而且图片链接早已失效，极大误导。总算清扫了。

2.全面淘汰DX12环境，改用DML插件。所以现在AMD的ME和SAEHD都和CUDA统一版本了。
之前升1.8.6版本的时候，DX12用户还停留在1.5.4。因为代码不是同一套，很麻烦，差点放弃更新A卡支持。

3.之前只有N卡+ME 有新的summary表，现在N卡+SAEHD、A卡+ME、A卡+SAEHD 都有新的表格排版了。

4.环境删减了一半，节省了解压后的体积。

5.不把RG强行捆绑，做成可选项。因为他影响很大：
【神农汉化】RG（显存优化）和DML（A卡）非常重要的测评-【DFL】综合讨论-deepfacelab中文网 - Powered by Discuz! (dfldata.cc)

6.A卡现在也支持RG了（因为DML接口与CUDA的写法统一）

备注：神农的优势在于环境 14合1
（官方20系，官方30系，官方dx12，官方dml，
官方20系RG，官方30系RG，官方dmlRG,
ME20系，ME30系，MEdx12，MEdml，
ME20系RG，ME30系RG，MEdmlRG,）
这就是神农整合包的神奇之处。

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月18日：
v1.8.6版本（完整包）：

1.周末没时间测试，补丁的插件缺了半截 补了。

2.经过多轮修改，现在的true和false改成是否了。

3.虽然这次1.8+版本只更新了CUDA-ME的，A卡和原版的仍然保持1.5.4左右的水平。我个人是没怎么出现BUG的。

4.打算暂时把ME的更新告一段落了，转头去把原版做的更简单易用！
【神农MVE-DFL汉化】v3.0.1
【神农MVE-DFL汉化】v3.0.1

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月17日：
v1.8.3版本：

1.还好下载的人不多，补上了表格的插件补丁（今天群友反馈缺表格就报错）

2.修改了大量的错别字和符号的对齐。 当然，不影响使用只影响美观，1.8.0用户别担心。

3.收到了建议说把true和false改成中文，好的 我也是这么想的

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月16日：
v1.8.0版本：

0.记得运行“初始化.bat”，它是用来对齐txt的表格的，其实包括原版和ICE的表格也能变整齐

1.全面重构summary的显示格式，包括txt也是整齐的
由于怕还有什么疏漏，我先不上传完整包，而是一个补丁~

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月14日：
v1.7.3版本：

1.增加作者名且写死到模型二进制里面，不能像options那样轻易删除

PS：其实五彩和猫的广告是在options，以我现在的掌握阶段，很容易删改。
yaml是可以任意添加和删除options的，也就是你可以直接在yaml
#新起一行，写
XXX:XXX
其实它就会覆盖dat，并且一直在。除非用yaml的方式修改。

2.未完成的功能预期：作者把模型加密授权给 机器码MAC-key的形式，绑定多台机器也可以。
保证每个作者和每个机器都是不同key
（比较有把握能搞成，大概2天时间）

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年3月13日：
v1.7.0版本：

1.全面修改yaml一键训练参数（或许能实现训练过程中的热修改）

2.有心做yaml汉化但是大分类上要抛弃英语，具体的key又必须是英语。总之不能双语共存。

3.毕竟我其他地方全都是双语显示，希望大家学熟练之后能够得心应手的修改yaml，否则只能我或者朋友做个UI了。

-----------------------------------------------------------------------------------------------------------------------------------------------------------

2024年2月28日：
v1.6.2版本：

1.修改训练bat的路径错误

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年2月27日：
v1.6.1版本：

1.汉化了2个合成器。其中原版的合成器用了猫之汉化的图片

2.SAEHD支持两种合成器

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年2月26日：
v1.6.0版本：

1.修改一些bat内容的错误，并增加一些文字介绍。

2.简化与合并—[ 模型 训练 —— Train Models ]—的功能
比如AMP不再区分SRC-SRC 以免误导新人，本质上只是修改bat里的路径罢了。

3.自动读写配置文件（一键开始训练），合并到常规训练，用询问的方式取代等待2秒。

4.确定了A卡能完整使用ME和SAEHD的训练。
我应该是全网第一个做多合一的版本（3种显卡版本x2种模型架构，附RG）
其中ME分支的A卡训练我也是通过改代码的方式。不然还可以尝试下载一个接口插件。

5.温馨提示：强烈推荐cc-aug的色彩迁移模式，效果非常好！但是这个功能不能用RG优化，只能先切换到DX12（哪怕你是N卡）

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年2月5日：
v1.5.4版本：

1.修复模型应用的bat菜单伸缩bug

2.使用SAEHD合成人脸bat的时候call正确的环境

3.导出dfm的bat也链接到对应的环境，改正模型架构名

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年2月1日：
v1.5.2版本：注意了！本次虽然改动很大，但没有给大版本号（主要是修复，不是新功能）
这次是补丁不是完整包！请覆盖到1.5.0版本！

1.ME和SAEHD模型训练全面支持A卡（之前比较仓促，今天积极检查和迁移算法）
备注：ME的A卡训练仍需测试，不报错是第一步。
它的眼嘴训练暂时无效。需要有人协助测试！

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月31日：
v1.5.1版本：

1.修复了导出dfm的路径错误（三种模型）

2.修改了ME合成的bat错误

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月30日：
v1.5.0版本：

1.环境改动，Landmarks 自动识错应该不报错了

2.终于解决了遗留了很久的问题！就是模型改名的时候报错原因居然是...

我已经做了处理，在提示错误原因的同时，也让脚本继续执行，而不是终止。

3.下一个版本应该会简化预训练的可选参数

4.下个版本想办法明确的提示OOM是显存或虚拟内存不足，并且给出建议提示。跳出好几页的代码 对新手不友好。

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月29日：
v1.4.2版本：

1.预训练继续解锁一些参数限制，比如说RW（随机扭曲），禁用一些参数

2.粗心大意发现FP16没有开放完全，漏了个地方已补。

3.下一个版本：基于if self.is_first_run() 看看要搞点什么引导

5.提醒：如果是A卡用户，用了切换环境后，也许只能使用SAEHD训练，不能使用ME，有A卡用户请私聊我交流。

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月28日：还有点问题，暂时不发了，等1.4.2一起解决
v1.4.1版本：

【神农MVE-DFL汉化】v3.0.1

1.想挽救一下“预训练”流程，大家都不用，为何不把这一项删掉？

2.按照官方默认的预训练转正时，不再强制清除inter和迭代数，而是询问用户。

3.开放了FP16，有没有勇士想试试？记得输入“?”看该参数说明

4.详细解释了 -udtc 每个参数的作用，详情请在训练控制台输入“?”

5.由于重新开放了FP16，所以gan不会报错了。但是ME版的gan据说只能选择1个GPU序号。

6. Landmarks自动识错 的bat里面路径写错了。已改

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月25日：
v1.4.0版本：

1.重大更新！N卡支持RG优化！小显存可以跑大一点的模型，或者增加BS上限
fp16仍然禁用，它是牺牲效果换取速度，令人无语。开发组伙伴想研究混合精度

2.ME和DFL 两个框架都支持N卡RG，而A卡不支持，试过了
DFL之前为了大家统一能用，是用DX12版本，所以N卡效率有折扣，
现在已经剥离开了，在训练时通过数字1和2来选择驱动类型！

这次的整合包结合了12个dfl版本合一。但是安装包的体积无明显增大。
（包括原版、ME，叠加是否RG，再乘以20系30系和A卡三种安装包）
（ME_A卡版本可能会在RG的时候出错，请联系我，毕竟A卡用户太少了）

3.内置了Landmarks自动识错、aligned合并工具，位置在bat的
第8类：——[ 其他 测试 —— Extra Function ]——  下面

4.由于fp16选项缺失导致开gan报错，忘记修复了。解决方法请看评论区置顶

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月18日：抱歉！消失的一周每天外出
v1.3.2版本：

1.上次1.3版的SAEHD还不是完全的原生，这次是了

2.对一些bat进行纠错，增加了ME模型的合成和导出

3.修复一个未知错误：模型改名报错（检查了一整天源码没问题，怀疑是pyc缓存的问题），
最后是通过回滚版本解决的

4.预训练集挪到了workspace因为经常要和aligned文件夹交换

5.xseg模型在workspace也有独立的目录了。不想跟脸模型混在一起

6.已经在研究如何极致压缩训练集了。目前的src保存于恢复数据非常积累，将来可以利用它！

7.已经顺藤摸瓜RO优化、eye模型、AVATAR模型、多GPU（超过3卡）训练。也是费了些时间收集，源码都拿到了

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月11日：
v1.3.0版本：

1.解决了原版SAEHD嫁接的BUG

2.由于DFL到ME容易升版不易降版，对于模型名称做了区分，免得误操作。
SAEHD-ME 简称SAEME模型或ME模型！

3.增加一个模型转换bat，目前只能从原版升ME

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月10日：
v1.2.3失败版本（仅记录）：

1.植入了原版DFL模型，但是出了点问题

2.明天继续，主要报错是EYE_MOUTH

3.下一个版本可能会把ME版的SAEHD改名为SAEME避免随意转换

4.下下版本增加原版和ME的转换bat

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月9日：
v1.2.2版本：

1.支持A卡，并附带一个切换显卡的bat

2.从原版升级时ada锁死

3.创建模型后，禁用ada选项（如同三围不可改）

4.全面取消fp16的选择

5.保留原生环境（基于DX12版本）并补充了jsonschema和attr

6.初始化的时候提供选项：可去除佛像和猫

7.从1.2.1版本开始，就不是补丁，而是完整的整合包了
备注：10系、20系、30系N卡；DX12 都集成到同一个压缩包了

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月7日：
多功能启动UI：
DFL-MVE 神农汉化版多功能启动UI-【DFL】软件下载

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月5日：
v1.1.1版本：

1.“导出loss”的bat指向的环境改为python3.9

2.python3.6.8原生环境补充attr依赖

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2024年1月4日
v1.1.0版本：

1.更改欢迎界面加两只猫

2.5个bat文件修改错误的预训练路径“pretrain_Celeb”

3.loss导出（让大家都知道总好过只有少数人知道）

4.再次更新tensorflow和cuda、cudnn（老显卡并没有提速）

5.python368原环境已补充了jsonschema

6.增加了免责声明

-----------------------------------------------------------------------------------------------------------------------------------------------------------
2023年12月29日
v1.0.0版本：

用法：覆盖到原版的安装目录

介绍：原作者是MachineEditor组织的Cioscos、seranus、Payuyi、AnkurSaini07

其实在GitHub通过【Deepfacelab】关键词能搜出来的结果只有千分之一

搜索关键词【deepfacelab fork:true】只有这样才能找到好东西！比如MachineEditor。

MVE功能：新增参数（包括但不限于）

[n] Use fp16 ( y/n ?:help ) :这个直接不要开，模型可能会崩掉

[n] Eyes priority ( y/n ?:help ) :单独的眼睛训练

[n] Mouth priority ( y/n ?:help ) :单独的嘴巴训练

[SSIM] Loss function ( SSIM/MS-SSIM/MS-SSIM L1 ?:help ) :这个好像是通过人脸相似度算法来计算loss的，自己搜索术语吧，保持默认就好。

[5e-05] Learning rate ( 0.0 .. 1.0 ?:help ) :学习率一般不去动它，你也可以手动的控制学习率下降，比如我在loss到0.25的时候改为3e-05

[n] Enable random downsample of samples ( y/n ?:help ) :跟随机扭曲同理，增强泛化性：随机降低分辨率

[n] Enable random noise added to samples ( y/n ?:help ) :跟随机扭曲同理，增强泛化性：随机噪点图

[n] Enable random blur of samples ( y/n ?:help ) :跟随机扭曲同理，增强泛化性：随机模糊图

[n] Enable random jpeg compression of samples ( y/n ?:help ) :跟随机扭曲同理，增强泛化性：随机压缩图片质量

[none] Enable random shadows and highlights of samples  :比较高级的随机，增强泛化性：随机模拟光影训练

新增的光影色彩学习算法："fs-aug", "cc-aug"
